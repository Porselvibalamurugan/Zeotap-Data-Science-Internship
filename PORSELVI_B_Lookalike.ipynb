{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAVt2nBUVRAd",
        "outputId": "a906cc77-e28a-4d22-e219-2fd2686ae857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
            "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
            "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
            "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
            "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
            "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
            "\n",
            "   TotalValue  Price_x                      ProductName     Category  Price_y  \\\n",
            "0      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "1      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "2      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "3      601.36   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "4      902.04   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "\n",
            "      CustomerName         Region  SignupDate  \n",
            "0   Andrea Jenkins         Europe  03-12-2022  \n",
            "1  Brittany Harvey           Asia  04-09-2024  \n",
            "2  Kathryn Stevens         Europe  04-04-2024  \n",
            "3  Travis Campbell  South America  11-04-2024  \n",
            "4    Timothy Perez         Europe  15-03-2022  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "customers = pd.read_csv('Customers.csv')\n",
        "transactions = pd.read_csv('Transactions.csv')\n",
        "products = pd.read_csv('Products.csv')\n",
        "\n",
        "# Merge transactions with product information\n",
        "transactions = transactions.merge(products, on='ProductID', how='inner')\n",
        "\n",
        "# Merge customer information\n",
        "data = transactions.merge(customers, on='CustomerID', how='inner')\n",
        "\n",
        "# Preview the combined data\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRh9uTAQVlLi",
        "outputId": "ea6baa7f-51eb-4769-a127-20c91d72447a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CustomerID     C0001     C0002     C0003     C0004     C0005     C0006  \\\n",
            "CustomerID                                                               \n",
            "C0001       1.000000  0.298255  0.349927  0.438417  0.984110  0.411723   \n",
            "C0002       0.298255  1.000000  0.275652  0.348556  0.246927  0.318325   \n",
            "C0003       0.349927  0.275652  1.000000  0.396076  0.300648  0.393963   \n",
            "C0004       0.438417  0.348556  0.396076  1.000000  0.344429  0.938406   \n",
            "C0005       0.984110  0.246927  0.300648  0.344429  1.000000  0.367057   \n",
            "\n",
            "CustomerID     C0007     C0008     C0009     C0010  ...     C0191     C0192  \\\n",
            "CustomerID                                          ...                       \n",
            "C0001       0.979384  0.414004  0.214254  0.288285  ...  0.361895  0.990921   \n",
            "C0002       0.272068  0.338211  0.988409  0.999680  ...  0.287675  0.248935   \n",
            "C0003       0.337496  0.908210  0.197045  0.265422  ...  0.334009  0.289815   \n",
            "C0004       0.375696  0.527879  0.252444  0.339231  ...  0.975185  0.361359   \n",
            "C0005       0.994614  0.305460  0.175606  0.236694  ...  0.298511  0.991110   \n",
            "\n",
            "CustomerID     C0193     C0194     C0195     C0196     C0197     C0198  \\\n",
            "CustomerID                                                               \n",
            "C0001       0.364170  0.397909  0.402311  0.412374  0.983761  0.223076   \n",
            "C0002       0.285603  0.319123  0.318707  0.313752  0.241361  0.982470   \n",
            "C0003       0.343861  0.359209  0.986483  0.953330  0.292573  0.214633   \n",
            "C0004       0.954738  0.994544  0.476565  0.437843  0.337456  0.240780   \n",
            "C0005       0.315700  0.312257  0.327729  0.378888  0.999767  0.201540   \n",
            "\n",
            "CustomerID     C0199     C0200  \n",
            "CustomerID                      \n",
            "C0001       0.989159  0.424803  \n",
            "C0002       0.244655  0.952370  \n",
            "C0003       0.283605  0.399714  \n",
            "C0004       0.355762  0.480586  \n",
            "C0005       0.989473  0.365249  \n",
            "\n",
            "[5 rows x 200 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Convert dates to datetime\n",
        "customers['SignupDate'] = pd.to_datetime(customers['SignupDate'],format='%d-%m-%Y')\n",
        "transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])\n",
        "\n",
        "# Aggregate transaction data\n",
        "transaction_features = transactions.groupby('CustomerID').agg({\n",
        "    'TotalValue': ['sum', 'mean'],\n",
        "    'ProductID': 'nunique', \n",
        "    'Category': lambda x: x.mode()[0]  \n",
        "}).reset_index()\n",
        "\n",
        "# Rename columns\n",
        "transaction_features.columns = ['CustomerID', 'TotalSpending', 'AvgTransactionValue', 'UniqueProducts', 'TopCategory']\n",
        "\n",
        "# Encode TopCategory\n",
        "transaction_features = pd.get_dummies(transaction_features, columns=['TopCategory'], prefix='Category')\n",
        "\n",
        "# Merge with customer data\n",
        "customer_data = customers.merge(transaction_features, on='CustomerID', how='left')\n",
        "\n",
        "# Select features for similarity calculation\n",
        "features = customer_data.drop(['CustomerID', 'SignupDate'], axis=1)\n",
        "\n",
        "# Handle missing values by filling them with 0\n",
        "features = features.fillna(0)\n",
        "\n",
        "# Convert non-numeric columns to numeric \n",
        "features = features.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "normalized_features = scaler.fit_transform(features)\n",
        "\n",
        "# Compute cosine similarity\n",
        "similarity_matrix = cosine_similarity(normalized_features)\n",
        "\n",
        "# Convert similarity matrix to a DataFrame\n",
        "similarity_df = pd.DataFrame(similarity_matrix, index=customer_data['CustomerID'], columns=customer_data['CustomerID'])\n",
        "\n",
        "# Summary\n",
        "print(similarity_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ04SxrcdCQg",
        "outputId": "a0b4016a-625b-4dcc-e525-789977d84e51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type of similarity_df index: object\n",
            "Data type of customer_data['CustomerID']: object\n",
            "No missing customers found.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Ensure the customer IDs in similarity_df and customer_data match types (string) \n",
        "similarity_df.index = similarity_df.index.astype(str)  \n",
        "similarity_df.columns = similarity_df.columns.astype(str)  \n",
        "customer_data['CustomerID'] = customer_data['CustomerID'].astype(str)  \n",
        "# Debugging: Check the data types\n",
        "print(\"Data type of similarity_df index:\", similarity_df.index.dtype)\n",
        "print(\"Data type of customer_data['CustomerID']:\", customer_data['CustomerID'].dtype)\n",
        "\n",
        "# Strip spaces from customer IDs  for correct comparison \n",
        "similarity_df.index = similarity_df.index.str.strip()  \n",
        "customer_data['CustomerID'] = customer_data['CustomerID'].str.strip()  \n",
        "\n",
        "# Debugging: Check for missing customers in similarity_df\n",
        "missing_customers = [customer for customer in customer_data['CustomerID'][:20] if customer not in similarity_df.index]\n",
        "\n",
        "# Print missing customers \n",
        "if missing_customers:\n",
        "    print(\"Missing Customers from similarity_df index:\")\n",
        "    for customer in missing_customers:\n",
        "        print(f\"Customer {customer} not found in similarity_df index\")\n",
        "else:\n",
        "    print(\"No missing customers found.\")\n",
        "\n",
        "# Initialize the lookalike map\n",
        "lookalike_map = {}\n",
        "\n",
        "# Iterate over the first 20 customers\n",
        "for customer_id in customer_data['CustomerID'][:20]:\n",
        "    if customer_id in similarity_df.index:  # Check if customer_id exists in similarity_df\n",
        "        # Get similarity scores for this customer\n",
        "        scores = similarity_df.loc[customer_id].sort_values(ascending=False)\n",
        "\n",
        "        # Exclude the customer itself \n",
        "        top_3 = scores.iloc[1:4]  # Take the next 3 highest scores\n",
        "        lookalike_map[customer_id] = [(other_id, round(score, 2)) for other_id, score in top_3.items()]\n",
        "    else:\n",
        "        print(f\"Customer ID {customer_id} not found in similarity matrix. Skipping...\")\n",
        "\n",
        "# Convert into a DataFrame\n",
        "lookalike_df = pd.DataFrame({'CustomerID': lookalike_map.keys(), 'Lookalikes': lookalike_map.values()})\n",
        "\n",
        "# Save as CSV file\n",
        "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
